apply plugin: "de.undercouch.download"
apply plugin: "ch.so.agi.gretl"

import ch.so.agi.gretl.api.TransferSet
import ch.so.agi.gretl.tasks.*
import java.nio.file.Paths
import java.nio.file.Files
import de.undercouch.gradle.tasks.download.Download

def pathToTempFolder = System.getProperty("java.io.tmpdir")
def pathToPdfExportFolder = Files.createTempDirectory("oerebadaeinzelschutz-").toFile().getAbsolutePath()

def iliModelBasis = "OeREBKRM_V2_0"
def iliModelTransferstruktur = "OeREBKRMtrsfr_V2_0"
def iliModelSymbole = "SO_AGI_OeREB_Legendeneintraege_20211020"

def dbSchemaEinzelschutzDenkmalOereb = "ada_denkmalschutz_oerebv2"
def interlisModelDir = "https://models.interlis.ch/;https://models.geo.admin.ch/;%ILI_FROM_DB"

def einzelschutzDenkmalDataSet = "ch.so.ada.oereb_einzelschutz_denkmal"
def symbolsDenkmalFlaecheDataSet = einzelschutzDenkmalDataSet + "_flaeche.symbole" 
def symbolsDenkmalPunktDataSet = einzelschutzDenkmalDataSet + "_punkt.symbole" 
def symbolsDataSets = [symbolsDenkmalFlaecheDataSet, symbolsDenkmalPunktDataSet]

def xtfFileName = einzelschutzDenkmalDataSet + "_V2_0.xtf"
def xtfZipFileName = einzelschutzDenkmalDataSet + "_V2_0_xtf.zip"
def emptyTransferFile = "ch.so.ada.oereb_einzelschutz_denkmal.empty.xtf"

def bucketSuffix = '-undefined'
if ( gretlEnvironment == 'production' ) {
    bucketSuffix = ''
} else if ( gretlEnvironment == 'integration' || gretlEnvironment == 'dev' ) {
    bucketSuffix = '-' + gretlEnvironment.substring(0, 3)
} else {
    bucketSuffix = '-' + gretlEnvironment
}

def responsibleOfficesBaseUrl = "https://s3.eu-central-1.amazonaws.com/ch.so.agi.geodata$bucketSuffix/"
def responsibleOfficesDataSet = "ch.so.agi.oereb_zustaendigestellen_V2_0"

def s3AdaStageBucket = "ch.so.ada.denkmal-stage$bucketSuffix"
def s3AdaLiveBucket = "ch.so.ada.denkmal$bucketSuffix"

def s3AgiTargetBucket = "ch.so.agi.geodata$bucketSuffix"

task deleteFromOereb(type: SqlExecutor) {
    description = "Löscht die Daten aus dem Transferschema."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlFiles = ["delete_oereb_einzelschutz_denkmal_tables.sql"]
}

task downloadResponsibleOffices(type: Download, dependsOn: 'deleteFromOereb') {
    doFirst {
        println responsibleOfficesBaseUrl + responsibleOfficesDataSet + ".xtf"
    }
    description = "Download zuständige Stellen ($responsibleOfficesDataSet)."
    src responsibleOfficesBaseUrl + responsibleOfficesDataSet + ".xtf"
    dest pathToTempFolder
    overwrite true
}

task importResponsibleOfficesToOereb(type: Ili2pgReplace, dependsOn: 'downloadResponsibleOffices') {
    description = "Import zuständige Stellen ($responsibleOfficesDataSet)."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelBasis
    modeldir = interlisModelDir
    dbschema = dbSchemaEinzelschutzDenkmalOereb
    dataFile = file(Paths.get(pathToTempFolder.toString(), responsibleOfficesDataSet + ".xtf"))
    importBid = true
    dataset = responsibleOfficesDataSet
}

symbolsDataSets.each { symbolsDataSet ->
    def symbols = symbolsDataSet.toString()
    task "importSymbolsToOereb_$symbols"(type: Ili2pgReplace, dependsOn: "deleteFromOereb") {
        description = "Import der Symbole $symbols"
        database = [dbUriEdit, dbUserEdit, dbPwdEdit]
        dbschema = dbSchemaEinzelschutzDenkmalOereb
        dataset = symbols
        models = iliModelSymbole
        modeldir = interlisModelDir
        dataFile = file(Paths.get("$rootDir", symbols + ".xtf"))
        disableValidation = true
        importBid = true
        importTid = true
    }
}

task importSymbolsToOereb() {
    description = "Aggregationstask für Import der Symbole."

    dependsOn {
        tasks.findAll { task -> task.name.startsWith('importSymbolsToOereb_') }
    }    
}

task importEmptyTransferToOereb(type: Ili2pgReplace, dependsOn: 'deleteFromOereb') {
    description = "Import eines leeren Grund-Basket damit notwendige Datasets- und Basketrecords für Transferdaten in der DB erstellt werden."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelTransferstruktur
    modeldir = interlisModelDir
    dbschema = dbSchemaEinzelschutzDenkmalOereb
    dataFile = file(emptyTransferFile)
    importBid = true
    dataset = einzelschutzDenkmalDataSet
}
/* HIER ANPASSEN!!! */
task transferData(type: SqlExecutor, dependsOn: ["deleteFromOereb", "importResponsibleOfficesToOereb", "importSymbolsToOereb", "importEmptyTransferToOereb"]) {
    description = "Führt den Datenumbau in das Transferschema durch."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    sqlParameters = [s3AdaLiveBucket: "'" + s3AdaLiveBucket + "'"]
    sqlFiles = ["insert_oereb_einzelschutz_denkmal_tables.sql"]
}

task exportData(type: Ili2pgExport, dependsOn: "transferData") {
    description = "Exportiert die umgebauten Daten aus dem Transferschema in ein INTERLIS-Datei."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    models = iliModelTransferstruktur
    dbschema = dbSchemaEinzelschutzDenkmalOereb
    dataFile = file(Paths.get("$rootDir", xtfFileName))
    dataset = einzelschutzDenkmalDataSet
    disableValidation = true
}

task replaceWmsServer(dependsOn: "exportData") {
    description = "Ersetzt verschiedene Elemente (Host, Pfad, etc.) der WMS-Requests."
    doLast {
        ant.replace(
        file: file(Paths.get("$rootDir", xtfFileName)),
        token: '${wmsHost}',
        value: 'https://' + geoservicesHostName,
        encoding: 'UTF-8')
    }
}

task validateData(type: IliValidator, dependsOn: "replaceWmsServer") {
    description = "Validiert die exportierten Daten in der Transferstruktur inkl. der externen Beziehungen."
    dataFiles = [
                 file(Paths.get(pathToTempFolder.toString(), responsibleOfficesDataSet + ".xtf")), 
                 file(Paths.get("$rootDir", xtfFileName))
                ]
    logFile = "ilivalidator.log"
    allObjectsAccessible = true
}
/* Braucht es nicht mehr weil Files jetzt woanders liegen!
task exportPdfFromDatabase(type: DatabaseDocumentExport, dependsOn: "validateData") {
    description = "PDF aus Datenbank exportieren."
    database = [dbUriEdit, dbUserEdit, dbPwdEdit]
    qualifiedTableName = "ada_denkmalschutz.fachapplikation_rechtsvorschrift_link"
    documentColumn = "multimedia_link"
    targetDir = file(pathToPdfExportFolder)
    fileNamePrefix = "ada_"
    fileNameExtension = "pdf"
}

task uploadPdfToS3Stage(type: S3Upload, dependsOn: "exportPdfFromDatabase") {
    description = "PDF aus Verzeichnis nach S3 hochladen."
    accessKey = awsAccessKeyAda
    secretKey = awsSecretAccessKeyAda
    sourceDir = file(pathToPdfExportFolder)
    endPoint = "https://s3.eu-central-1.amazonaws.com"
    region = "eu-central-1"
    bucketName = s3AdaStageBucket
    acl = "public-read"
}
*/
task importDataToStage(type: Ili2pgReplace, dependsOn: "validateData") {
//task importDataToStage(type: Ili2pgReplace) {
    description = "Import des Einzelschutz-ÖREB-Datensatz in das Stage-Schema."
    database = [dbUriOerebV2, dbUserOerebV2, dbPwdOerebV2]
    models = iliModelTransferstruktur
    dbschema = "stage"
    dataFile = file(Paths.get("$rootDir", xtfFileName))
    dataset = einzelschutzDenkmalDataSet
    importBid = true
    importTid = true
    disableValidation = true
    finalizedBy {
        updateS3StageLink
    }
}

task updateS3StageLink(type: SqlExecutor) {
    description = "Setzt den Link der PDF auf die Stage-Umbebung"
    database = [dbUriOerebV2, dbUserOerebV2, dbPwdOerebV2]
    sqlFiles = ["update_rechtsvorschriften_localiseduri.sql"]
}

task refreshOerebWMSTablesStage(type: SqlExecutor) {
    description = "Aktualisiert OEREB WMS Tabellen."
    database = [dbUriOerebV2, dbUserOerebV2, dbPwdOerebV2]
    sqlFiles = ["update_oerebwms_tables.sql"]
    sqlParameters = [dbSchema: 'stage']
}

/* Es müssen keine PDFs mehr nach S3 kopiert werden
task copyPdfToS3Live(type: S3Bucket2Bucket) {
    accessKey = awsAccessKeyAda
    secretKey = awsSecretAccessKeyAda
    sourceBucket = s3AdaStageBucket
    targetBucket = s3AdaLiveBucket
    acl = "public-read"
}
*/

task importDataToLive(type: Ili2pgReplace, dependsOn: "refreshOerebWMSTablesStage") {
//task importDataToLive(type: Ili2pgReplace) {
    description = "Import des Einzelschutz-ÖREB-Datensatz in das Live-Schema."
    database = [dbUriOerebV2, dbUserOerebV2, dbPwdOerebV2]
    models = iliModelTransferstruktur
    dbschema = "live"
    dataFile = file(Paths.get("$rootDir", xtfFileName))
    dataset = einzelschutzDenkmalDataSet 
    importBid = true
    importTid = true
    disableValidation = true
}

task refreshOerebWMSTablesLive(type: SqlExecutor) {
    description = "Aktualisiert OEREB WMS Tabellen."
    database = [dbUriOerebV2, dbUserOerebV2, dbPwdOerebV2]
    sqlFiles = ["update_oerebwms_tables.sql"]
    sqlParameters = [dbSchema: 'live']
}

task zipXtfFile(type: Zip) {
    description = "Zipt das xtf-File mit den Einzelschutz-Denkmal-Daten für den Upload nach S3"
    from "$rootDir"
    include xtfFileName
    archiveName xtfZipFileName
    destinationDir(file("$rootDir"))
}

task uploadXtfToS3Geodata(type: S3Upload, dependsOn: "zipXtfFile") {
    description = "Xtf-File nach S3 hochladen."
    accessKey = awsAccessKeyAgi
    secretKey = awsSecretAccessKeyAgi
    sourceFile = file(Paths.get("$rootDir", xtfZipFileName))
    endPoint = "https://s3.eu-central-1.amazonaws.com"
    region = "eu-central-1"
    bucketName = s3AgiTargetBucket
    acl = "public-read"
}